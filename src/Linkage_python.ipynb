{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba5605d-603d-40fb-82a1-6a94ad271473",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1005412077.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install pandas\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef130e5a-b280-4228-b70e-f3b7794520a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qgrid\n",
      "  Downloading qgrid-1.3.1.tar.gz (889 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m889.2/889.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting notebook>=4.0.0 (from qgrid)\n",
      "  Downloading notebook-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>=0.18.0 in ./.venv/lib/python3.10/site-packages (from qgrid) (2.2.3)\n",
      "Collecting ipywidgets>=7.0.0 (from qgrid)\n",
      "  Downloading ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->qgrid) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->qgrid) (8.35.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->qgrid) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=7.0.0->qgrid)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets>=7.0.0->qgrid)\n",
      "  Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.0rc0 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (4.4.0)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (6.4.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2025.2)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (4.13.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (23.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (7.7.0)\n",
      "Requirement already satisfied: packaging>=22.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (25.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (26.4.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (0.28.1)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (78.1.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2.2.1)\n",
      "Requirement already satisfied: babel>=2.10 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.18.0->qgrid) (1.17.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (21.2.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (0.14.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (1.8.14)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (7.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (4.3.7)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./.venv/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2.4.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.2.3)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.4.0)\n",
      "Requirement already satisfied: fqdn in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.0.0)\n",
      "Requirement already satisfied: uri-template in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./.venv/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.6)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./.venv/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./.venv/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.9.0.20241206)\n",
      "Downloading ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "Downloading notebook-7.4.0-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: qgrid\n",
      "  Building wheel for qgrid (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for qgrid: filename=qgrid-1.3.1-py2.py3-none-any.whl size=1761343 sha256=98ea9338637a4c3e4ed5dd594b56ecc8b29236f14d138a312c059cfc63b138cb\n",
      "  Stored in directory: /home/pamela/.cache/pip/wheels/b2/28/9b/c1053eb92a506d814e21f415d6ce4beab694a3efed99b500bc\n",
      "Successfully built qgrid\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets, notebook, qgrid\n",
      "Successfully installed ipywidgets-8.1.6 jupyterlab_widgets-3.0.14 notebook-7.4.0 qgrid-1.3.1 widgetsnbextension-4.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install qgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f69f0b66-e8a9-4a61-8810-e35b25f33f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff88b81-6eec-4876-88e6-e1b451c5fea9",
   "metadata": {},
   "source": [
    "# Tabela de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c539c90-beeb-4099-b0e0-c86bc2b6e56e",
   "metadata": {},
   "source": [
    "Carrega a fun√ß√£o read_csv() do pacote pandas\n",
    "\n",
    "A fun√ß√£o read_csv() √© utilizada para ler arquivos CSV em Python.\n",
    "Ao utilizarmos o par√¢metro `sep=';'`, indicamos que o separador de colunas do arquivo √© o ponto e v√≠rgula (;)\n",
    "Esse √© o padr√£o de separa√ß√£o em muitos arquivos CSV gerados por sistemas brasileiros,\n",
    "como os arquivos exportados de sistemas p√∫blicos de sa√∫de\n",
    "\n",
    "L√™ o arquivo chamado \"sivep_identificado.csv\", que est√° dentro da pasta \"DATA\"\n",
    "Este arquivo cont√©m informa√ß√µes de interna√ß√µes por S√≠ndrome Respirat√≥ria Aguda Grave (SRAG), incluindo casos de COVID-19\n",
    "A base foi extra√≠da do sistema SIVEP-Gripe, utilizado para registrar e acompanhar esses casos no Brasil\n",
    "O nome do arquivo indica que os dados est√£o identificados (ou seja, possivelmente cont√™m nomes ou outros dados sens√≠veis que permitem identificar os pacientes)\n",
    "\n",
    "A fun√ß√£o read_csv() transforma esse arquivo CSV em um objeto do tipo DataFrame, que ser√° armazenado na vari√°vel `sivep`\n",
    "Essa vari√°vel agora cont√©m toda a base de dados de interna√ß√µes e poder√° ser manipulada, filtrada,\n",
    "cruzada com outras bases (como a de √≥bitos), analisada e visualizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e721940-a81b-4402-8a47-f7d0cca1f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Se os campos s√£o separados por ponto e v√≠rgula (padr√£o do Brasil, como arquivos do SUS):\n",
    "df = pd.read_csv('/home/pamela/Documentos/Linkage_Data_Health/DATA/sivep_identificado.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2e59b7-6691-4774-b17d-a7966c1a98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nu_notific                       nome       sexo   data_nasc  idade  \\\n",
      "0     10001569      Kauan Azevedo Azevedo  masculino  1965-07-27     57   \n",
      "1     10009876         Raissa Cunha Costa   feminino  1939-07-15     83   \n",
      "2     10012252      Rafael Castro Barbosa  masculino  1976-03-28     46   \n",
      "3     10012410     Vinicius Silva Ribeiro  masculino  1964-02-10     58   \n",
      "4     10017778       Beatriz Araujo Rocha   feminino  1992-03-04     30   \n",
      "..         ...                        ...        ...         ...    ...   \n",
      "95    10187056    Vitoria Correia Almeida   feminino  1979-07-25     43   \n",
      "96    10188551  Carlos Goncalves Carvalho  masculino  1972-12-16     49   \n",
      "97    10188869       Paulo Barros Almeida  masculino  1972-01-09     50   \n",
      "98    10189965   Guilherme Castro Barbosa  masculino  1951-12-04     70   \n",
      "99    10190488       Marisa Ribeiro Pinto   feminino  1961-12-13     60   \n",
      "\n",
      "               cpf                   nome_mae  \n",
      "0   622.290.767-95     Analia Azevedo Azevedo  \n",
      "1   662.957.878-35          Agata Cunha Costa  \n",
      "2   665.935.236-82     Natacha Castro Barbosa  \n",
      "3   532.933.567-10      Aldenir Silva Ribeiro  \n",
      "4   602.213.075-16          Raquel de Miranda  \n",
      "..             ...                        ...  \n",
      "95  155.195.378-10  Cleidiane Correia Almeida  \n",
      "96  121.244.102-88      Hilda Henrique Santos  \n",
      "97  337.997.565-66      Natali Barros Almeida  \n",
      "98  832.643.843-02    Grasiele Castro Barbosa  \n",
      "99  935.870.221-43        Aracy Ribeiro Pinto  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostra as primeiras linhas\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a2a02-8169-4619-824e-3628f88aa967",
   "metadata": {},
   "source": [
    "A visualiza√ß√£o abaixo mostra as primeiras linhas do DataFrame `sivep`, que cont√©m informa√ß√µes sobre interna√ß√µes\n",
    "por S√≠ndrome Respirat√≥ria Aguda Grave (SRAG), extra√≠das do sistema SIVEP-Gripe.\n",
    "Cada linha representa um paciente e as colunas trazem atributos relacionados √† identifica√ß√£o e caracter√≠sticas individuais.\n",
    "\n",
    "Explica√ß√£o das colunas apresentadas:\n",
    "- nu_notific: n√∫mero da notifica√ß√£o (identificador √∫nico do registro)\n",
    "- nome: nome completo do paciente\n",
    "- sexo: sexo biol√≥gico (masculino/feminino)\n",
    "- data_nasc: data de nascimento\n",
    "- idade: idade do paciente no momento da notifica√ß√£o\n",
    "- cpf: n√∫mero do CPF do paciente\n",
    "- nome_mae: nome completo da m√£e do paciente\n",
    "\n",
    "Essa tabela √© √∫til para realizar an√°lises de perfil demogr√°fico, validar registros por linkage com outras bases (ex: √≥bitos),\n",
    "ou realizar estudos epidemiol√≥gicos sobre os casos registrados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4cd232-a895-42a2-b6d3-537841abf8ef",
   "metadata": {},
   "source": [
    "# 2. Gerando e filtrando os pares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d172cd5-1e6b-4a6e-995a-6a4012e4e2ae",
   "metadata": {},
   "source": [
    "\n",
    "Realizando a blocagem dos dados pela vari√°vel \"sexo\"\n",
    "A fun√ß√£o 'pair_blocking' do pacote 'reclin' √© utilizada para blocar os dados\n",
    "especificando que a compara√ß√£o ser√° feita com base na vari√°vel \"sexo\".\n",
    "Isso ajuda a reduzir a quantidade de pares a serem comparados.\n",
    "O argumento 'deduplication = TRUE' indica que estamos realizando a deduplica√ß√£o,\n",
    "ou seja, comparando o banco de dados consigo mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e1feec9-f8c9-4681-b0fd-1952cd568a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nu_notific', 'nome', 'sexo', 'data_nasc', 'idade', 'cpf', 'nome_mae'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verificar as colunas para garantir que 'sexo' est√° presente\n",
    "print(df.columns)\n",
    "df=df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47909a-3fb4-4900-86d0-d658537bb679",
   "metadata": {},
   "source": [
    "Index(['nu_notific', 'nome', 'sexo', 'data_nasc', 'idade', 'cpf', 'nome_mae'], dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16c2fe5a-4b73-4ab2-aa2d-74fbcad37fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pares encontrados: 2454\n"
     ]
    }
   ],
   "source": [
    "# Realizando a blocagem dos dados pela vari√°vel \"sexo\"\n",
    "pares_blocagem = []\n",
    "\n",
    "# Agrupar os dados pelo sexo\n",
    "for sexo, grupo in df.groupby('sexo'):\n",
    "    # Para cada grupo, realizar a compara√ß√£o de todos os pares dentro do grupo\n",
    "    for i in range(len(grupo)):\n",
    "        for j in range(i + 1, len(grupo)):\n",
    "            pares_blocagem.append((grupo.iloc[i], grupo.iloc[j]))\n",
    "\n",
    "# Convertendo a lista de pares em um DataFrame para visualiza√ß√£o\n",
    "pares_blocagem_df = pd.DataFrame(pares_blocagem, columns=['Registro_1', 'Registro_2'])\n",
    "\n",
    "# Exibindo as primeiras linhas da tabela resultante da blocagem\n",
    "pares_blocagem_df.head()\n",
    "\n",
    "# Contando o total de pares encontrados\n",
    "total_pares = len(pares_blocagem_df)\n",
    "print(f'Total de pares encontrados: {total_pares}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "631a6e91-9588-4c4f-a9fa-13dd450f93f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: recordlinkage in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (0.16)\n",
      "Requirement already satisfied: jellyfish>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (2.2.4)\n",
      "Requirement already satisfied: pandas<3,>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.6.1)\n",
      "Requirement already satisfied: joblib in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from pandas<3,>=1->recordlinkage) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from pandas<3,>=1->recordlinkage) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from pandas<3,>=1->recordlinkage) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from scikit-learn>=1->recordlinkage) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1->recordlinkage) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install recordlinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb691e3-4482-4219-b2af-056a1a20ef17",
   "metadata": {},
   "source": [
    "# 3. Aplicando o m√©todo de linkage determin√≠stico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bfca0-1e2c-4a2d-a98a-46dc6cf61723",
   "metadata": {},
   "source": [
    "### üîß import recordlinkage\n",
    "\n",
    "Esse comando importa o pacote inteiro, permitindo acesso a todos os seus m√≥dulos, como:\n",
    "\n",
    "**recordlinkage.Index()** ‚Äì para definir blocagens e gerar pares de registros;\n",
    "\n",
    "**recordlinkage.Compare()** ‚Äì para comparar os pares gerados e calcular similaridades;\n",
    "\n",
    "**recordlinkage.ECMClassifier()** ‚Äì um classificador probabil√≠stico para decidir se pares s√£o correspond√™ncias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301cc38-9867-4884-a68f-c10c58632a82",
   "metadata": {},
   "source": [
    "### from recordlinkage import Compare\n",
    "Esse comando importa s√≥ a **classe Compare**, usada para:\n",
    "\n",
    "‚úÖ Definir como os registros ser√£o comparados\n",
    "Voc√™ define as vari√°veis a comparar, e o m√©todo de compara√ß√£o (ex: Jaro-Winkler, exata, Levenshtein etc).\n",
    "\n",
    "‚úÖ Calcular a similaridade dos pares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "657f50c4-41b8-403d-9344-ccb6768396f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage import Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb322642-75b5-424b-ae40-c9fe5cf1ce3b",
   "metadata": {},
   "source": [
    "Agora aplicaremos o linkage do tipo determin√≠stico. Isto porque com ele o pareamento dos indiv√≠duos no banco de dados √© feito pela correspond√™ncia exata entre registros. Vamos l√°!\n",
    "\n",
    "Como primeira etapa, iremos realizar o linkage informando quais vari√°veis queremos comparar. Em nosso exemplo, iremos utilizar as vari√°veis nome, data de nascimento, cpf e nome da m√£e.\n",
    "\n",
    "Ent√£o precisaremos comparar se os valores das vari√°veis s√£o iguais. Ao aplicar esta etapa poderemos obter os valores TRUE (verdadeiro) ou FALSE (falso). Para que voc√™ possa compreender melhor, se um par de registros no qual as quatro vari√°veis escolhidas fossem TRUE (verdadeiras) representaria um linkage com alta acur√°cia entre estes registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "261ad7dd-41da-418e-a0a0-b568c591f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criando o indexador e fazendo a blocagem por 'sexo'\n",
    "indexador = Index()\n",
    "indexador.block('sexo')\n",
    "\n",
    "# Gerando os pares de blocagem (isso retorna um pandas.MultiIndex)\n",
    "pares_blocagem = indexador.index(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "89c76cba-6b53-494c-9a3b-3d5e64fe1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_comparacao = compare.compute(pares_blocagem, df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b326d4e-8640-4433-9b66-8f454256e234",
   "metadata": {},
   "source": [
    "**Compare()**.exact(...): compara os valores de forma exata.\n",
    "\n",
    "**pares_iguais**: guarda apenas os pares em que todas as vari√°veis s√£o `iguais (1.0)`.\n",
    "\n",
    "**block('sexo')**: opcional, usado para reduzir o n√∫mero de pares comparados, fazendo compara√ß√µes s√≥ dentro de grupos (por exemplo, homens com homens e mulheres com mulheres).\n",
    "\n",
    "Ao final, o c√≥digo imprime os pares de registros que batem exatamente em todas as vari√°veis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f7ce9cd-1821-43c6-9bfb-e698cd34232b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x     y  nome  data_nasc   cpf  nome_mae\n",
      "0   528  3372  True       True  True      True\n",
      "1   933  6984  True       True  True      True\n",
      "2   978  3026  True       True  True      True\n",
      "3  1023  9323  True       True  True      True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suponha que voc√™ tenha um DataFrame de exemplo como este:\n",
    "# O DataFrame 'p_deter' √© o resultado da compara√ß√£o entre os registros, \n",
    "# onde as colunas 'nome', 'data_nasc', 'cpf' e 'nome_mae' cont√™m valores booleanos.\n",
    "# Aqui, vamos criar um DataFrame fict√≠cio para simular o exemplo:\n",
    "\n",
    "data = {\n",
    "    'x': [528, 933, 978, 1023],\n",
    "    'y': [3372, 6984, 3026, 9323],\n",
    "    'nome': [True, True, True, True],\n",
    "    'data_nasc': [True, True, True, True],\n",
    "    'cpf': [True, True, True, True],\n",
    "    'nome_mae': [True, True, True, True]\n",
    "}\n",
    "\n",
    "# Criando o DataFrame\n",
    "p_deter = pd.DataFrame(data)\n",
    "\n",
    "# Filtrando os pares com correspond√™ncia exata em todas as vari√°veis\n",
    "pares_iguais = p_deter[\n",
    "    p_deter[['nome', 'data_nasc', 'cpf', 'nome_mae']].all(axis=1)\n",
    "]\n",
    "\n",
    "# Exibindo os pares com correspond√™ncia perfeita\n",
    "print(pares_iguais)\n",
    "\n",
    "# A sa√≠da ser√° algo assim:\n",
    "#       x     y   nome  data_nasc   cpf  nome_mae\n",
    "# 0   528  3372   True   True     True    True\n",
    "# 1   933  6984   True   True     True    True\n",
    "# 2   978  3026   True   True     True    True\n",
    "# 3  1023  9323   True   True     True    True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcc612-b306-4ff3-a5f2-fa6f80d171ce",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " A sa√≠da ser√° algo assim:\n",
    " | x   |  y  | nome | data_nasc  | cpf |nome_mae|\n",
    "| ------  | :-----------------------: | ------  | :-----------------------: | ------  | :-----------------------: |\n",
    "| 0   |528 | 3372  | True   |True |    True|    True|\n",
    "| 1  | 933 | 6984 |  True |  True |    True|   True|\n",
    "| 2  | 978 | 3026 |  True  | True |  True |   True|\n",
    "| 3  |1023 | 9323 |  True  | True  |   True |   True|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19b08f-3cc9-45a9-a340-ccfb87687f87",
   "metadata": {},
   "source": [
    "Esse resultado mostra os pares de registros que foram identificados como iguais em todas as vari√°veis comparadas ‚Äî ou seja, possivelmente registros duplicados no seu dataset.\n",
    "\n",
    "\n",
    "üìã Descri√ß√£o do Resultado\n",
    "\n",
    "| Coluna | Significado |\n",
    "| ------  | :-----------------------: |\n",
    "| `x` |\t√çndice do primeiro registro no par comparado|\n",
    "| `y`\t|  √çndice do segundo registro no par comparado |\n",
    "| `nome` | `True` indica que os valores de nome s√£o iguais nos dois registros |\n",
    "| `data_nasc`\t| `True` indica que as datas de nascimento tamb√©m batem exatamente |\n",
    "| `cpf` |\t`True` significa que os dois registros t√™m o mesmo CPF |\n",
    "| `nome_mae` |\t`True` indica que os nomes das m√£es s√£o iguais |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8782ebc-b6c1-44e7-91ed-6929f47389e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (0.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ff666-a755-426e-beca-276a109a24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f1145-60f0-4cf2-9262-839c9abdf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique o n√∫mero de linhas no DataFrame# Verifique os √≠ndices em 'pares_iguais'\n",
    "print(pares_iguais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbb7c0-f265-4efb-b92b-7b592c6ebe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique o n√∫mero de linhas no DataFrame\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefc0f7-2c19-46c3-8923-d6eea6e037c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique o n√∫mero de linhas no DataFrame\n",
    "print(f\"Total de linhas no DataFrame: {len(df)}\")\n",
    "\n",
    "# Suponha que 'pares_iguais' seja um DataFrame com os √≠ndices dos pares duplicados\n",
    "# Exemplo de pares_iguais (√≠ndices das linhas duplicadas)\n",
    "pares_iguais = pd.DataFrame({'x': [528, 1034], 'y': [3372, 2104]})\n",
    "\n",
    "# Verifique se os √≠ndices est√£o dentro do intervalo\n",
    "if (pares_iguais['x'][0] < len(df)) and (pares_iguais['y'][0] < len(df)):\n",
    "    # Selecionando as linhas correspondentes aos √≠ndices dos pares duplicados\n",
    "    registro_1 = df.iloc[pares_iguais['x'][0]]\n",
    "    registro_2 = df.iloc[pares_iguais['y'][0]]\n",
    "\n",
    "    # Concatenando as duas linhas para visualiza√ß√£o\n",
    "    pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "\n",
    "    # Exibindo as duas linhas duplicadas em formato de tabela bonita\n",
    "    print(tabulate(pares_duplicados, headers='keys', tablefmt='pretty'))\n",
    "else:\n",
    "    print(\"√çndices fora do intervalo do DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919c6cb-55f0-44a9-8568-5032601eb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verifique o n√∫mero de linhas no DataFrame\n",
    "total_linhas = len(df)\n",
    "print(f\"Total de linhas no DataFrame: {total_linhas}\")\n",
    "\n",
    "# Suponha que 'pares_iguais' seja um DataFrame com os √≠ndices dos pares duplicados\n",
    "# Exemplo de pares_iguais (√≠ndices das linhas duplicadas)\n",
    "pares_iguais = pd.DataFrame({'x': [528, 1034], 'y': [3372, 2104]})\n",
    "\n",
    "# Verifique os √≠ndices em 'pares_iguais'\n",
    "print(\"√çndices em pares_iguais:\")\n",
    "print(pares_iguais)\n",
    "\n",
    "# Verifique se os √≠ndices est√£o dentro do intervalo\n",
    "for index_x, index_y in zip(pares_iguais['x'], pares_iguais['y']):\n",
    "    if index_x < total_linhas and index_y < total_linhas:\n",
    "        # Selecionando as linhas correspondentes aos √≠ndices dos pares duplicados\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "\n",
    "        # Concatenando as duas linhas para visualiza√ß√£o\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "\n",
    "        # Exibindo as duas linhas duplicadas em formato de tabela bonita\n",
    "        print(tabulate(pares_duplicados, headers='keys', tablefmt='pipe', showindex=False))\n",
    "    else:\n",
    "        print(f\"√çndices {index_x} ou {index_y} est√£o fora do intervalo do DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224eb5fa-3d67-42e8-8b0a-78d8aba740a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando pares_iguais para manter apenas os √≠ndices dentro do intervalo\n",
    "pares_iguais_filtrados = pares_iguais[(pares_iguais['x'] < total_linhas) & (pares_iguais['y'] < total_linhas)]\n",
    "\n",
    "# Verifique os pares filtrados\n",
    "print(\"Pares de √≠ndices v√°lidos:\")\n",
    "print(pares_iguais_filtrados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53436e-2443-4342-b8c5-f0f44bfafa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste manual dos √≠ndices (caso voc√™ saiba que esses s√£o inv√°lidos)\n",
    "pares_iguais.loc[0, 'x'] = 10  # Ajuste o √≠ndice conforme necess√°rio\n",
    "pares_iguais.loc[0, 'y'] = 20  # Ajuste o √≠ndice conforme necess√°rio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1375de2-9d2b-4868-bcb3-0807a9e17e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando pares_iguais para garantir que os √≠ndices est√£o dentro do intervalo\n",
    "pares_iguais_filtrados = pares_iguais[(pares_iguais['x'] < total_linhas) & (pares_iguais['y'] < total_linhas)]\n",
    "\n",
    "# Se houver pares v√°lidos\n",
    "if not pares_iguais_filtrados.empty:\n",
    "    for index_x, index_y in zip(pares_iguais_filtrados['x'], pares_iguais_filtrados['y']):\n",
    "        # Selecionando as linhas correspondentes aos √≠ndices dos pares duplicados\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "\n",
    "        # Concatenando as duas linhas para visualiza√ß√£o\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "\n",
    "        # Exibindo as duas linhas duplicadas em formato de tabela bonita\n",
    "        print(tabulate(pares_duplicados, headers='keys', tablefmt='pipe', showindex=False))\n",
    "else:\n",
    "    print(\"Nenhum √≠ndice v√°lido encontrado em pares_iguais\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eae549-9dc2-4b8d-b369-e57a87c2c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage import compare\n",
    "from recordlinkage.index import Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e861ff-bf55-40e1-a862-456e044e1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pares_blocagem.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ab893-03d7-4259-b10e-e44b97e72903",
   "metadata": {},
   "outputs": [],
   "source": [
    "pares_blocagem.rename(columns={'nome_coluna_diferente': 'nome'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42c10f-8a8c-46ec-b4d6-44306a34c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pares_blocagem.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4d961-aab1-48cb-bd6c-92a09e54c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install recordlinkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b734b2c-10ef-4ead-83e4-bbc513826ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage import Index\n",
    "from recordlinkage.preprocessing import clean\n",
    "from recordlinkage import Compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd599dda-fc6a-4e54-b8fd-5afa6645622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supondo que voc√™ tenha um DataFrame 'df' com as colunas 'nome', 'data_nasc', 'cpf', 'nome_mae'\n",
    "\n",
    "# Limpeza de dados, como remo√ß√£o de espa√ßos extras e convers√£o de mai√∫sculas/min√∫sculas\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Cria√ß√£o do √≠ndice de compara√ß√£o\n",
    "indexer = Index()\n",
    "indexer.block('nome')  # Comparando primeiro pelo nome\n",
    "pairs = indexer.index(df)\n",
    "\n",
    "# Compara√ß√£o de pares\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Adicionando compara√ß√µes para as colunas\n",
    "compare.string('nome', 'nome', threshold=0.9, label='nome')\n",
    "compare.string('cpf', 'cpf', threshold=0.9, label='cpf')\n",
    "compare.string('nome_mae', 'nome_mae', threshold=0.9, label='nome_mae')\n",
    "compare.string('data_nasc', 'data_nasc', threshold=0.9, label='data_nasc')\n",
    "\n",
    "# Comparando os pares\n",
    "features = compare.compute(pairs, df)\n",
    "\n",
    "# Resultados: Filtrando os pares com alta similaridade\n",
    "matches = features[features.sum(axis=1) > 2]  # Ajuste o n√∫mero conforme necess√°rio\n",
    "\n",
    "# Exibindo os pares com alta similaridade\n",
    "if not matches.empty:\n",
    "    for index_x, index_y in matches.index:\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "        print(pares_duplicados.to_string(index=False))\n",
    "else:\n",
    "    print(\"Nenhum par duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adb757-805e-4c61-9693-39204126a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import recordlinkage\n",
    "# from recordlinkage import Index\n",
    "# from recordlinkage.preprocessing import clean\n",
    "# from recordlinkage import Compare\n",
    "\n",
    "# Supondo que voc√™ tenha um DataFrame 'df' com as colunas 'nome', 'data_nasc', 'cpf', 'nome_mae'\n",
    "\n",
    "# Limpeza de dados, como remo√ß√£o de espa√ßos extras e convers√£o de mai√∫sculas/min√∫sculas\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Verificando duplicatas diretamente\n",
    "print(df[df.duplicated(subset=['nome', 'cpf', 'nome_mae', 'data_nasc'], keep=False)])\n",
    "\n",
    "# Cria√ß√£o do √≠ndice de compara√ß√£o\n",
    "indexer = Index()\n",
    "indexer.block(['nome', 'data_nasc'])  # Alterando a estrat√©gia de bloqueio\n",
    "pairs = indexer.index(df)\n",
    "\n",
    "# Compara√ß√£o de pares\n",
    "compare = Compare()\n",
    "\n",
    "# Ajustando os limiares de similaridade para cada coluna usando o m√©todo 'string' com 'jaro_winkler'\n",
    "compare.string('nome', 'nome', threshold=0.7, label='nome', method='jaro_winkler')\n",
    "compare.string('cpf', 'cpf', threshold=0.8, label='cpf', method='jaro_winkler')\n",
    "compare.string('nome_mae', 'nome_mae', threshold=0.8, label='nome_mae', method='jaro_winkler')\n",
    "compare.string('data_nasc', 'data_nasc', threshold=0.6, label='data_nasc', method='jaro_winkler')\n",
    "\n",
    "# Comparando os pares\n",
    "features = compare.compute(pairs, df)\n",
    "\n",
    "# Exibindo as compara√ß√µes para diagn√≥stico\n",
    "print(features.head())\n",
    "\n",
    "# Resultados: Filtrando os pares com alta similaridade\n",
    "matches = features[features.sum(axis=1) > 0]  # Relaxando a condi√ß√£o para permitir mais matches\n",
    "\n",
    "# Exibindo os pares com alta similaridade\n",
    "if not matches.empty:\n",
    "    for index_x, index_y in matches.index:\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "        print(pares_duplicados.to_string(index=False))\n",
    "else:\n",
    "    print(\"Nenhum par duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbde46-c68c-4f80-9582-67cc4c007102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supondo que voc√™ tenha um DataFrame 'df' com as colunas 'nome', 'data_nasc', 'cpf', 'nome_mae'\n",
    "\n",
    "# Limpeza de dados, como remo√ß√£o de espa√ßos extras e convers√£o de mai√∫sculas/min√∫sculas\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Verificando duplicatas diretamente\n",
    "print(\"Verificando duplicatas diretamente:\")\n",
    "print(df[df.duplicated(subset=['nome', 'cpf', 'nome_mae', 'data_nasc'], keep=False)])\n",
    "\n",
    "# Criando o √≠ndice de compara√ß√£o\n",
    "indexer = Index()\n",
    "indexer.block(['sexo'])  # Alterando a estrat√©gia de bloqueio para 'sexo' (ajuste conforme necess√°rio)\n",
    "pairs = indexer.index(df)\n",
    "\n",
    "# Exibindo o n√∫mero total de pares\n",
    "print(f\"\\nN√∫mero total de pares: {len(pairs)} pares\")\n",
    "\n",
    "# Compara√ß√£o de pares\n",
    "compare = Compare()\n",
    "\n",
    "# Ajustando os limiares de similaridade para cada coluna usando o m√©todo 'string' com 'jaro_winkler'\n",
    "compare.string('nome', 'nome', threshold=0.7, label='nome', method='jaro_winkler')\n",
    "compare.string('cpf', 'cpf', threshold=0.8, label='cpf', method='jaro_winkler')\n",
    "compare.string('nome_mae', 'nome_mae', threshold=0.8, label='nome_mae', method='jaro_winkler')\n",
    "compare.string('data_nasc', 'data_nasc', threshold=0.6, label='data_nasc', method='jaro_winkler')\n",
    "\n",
    "# Comparando os pares\n",
    "features = compare.compute(pairs, df)\n",
    "\n",
    "# Exibindo o resumo de similaridade\n",
    "print(\"\\nResumo da similaridade:\")\n",
    "print(features.head())\n",
    "\n",
    "# Filtrando os pares com alta similaridade\n",
    "matches = features[features.sum(axis=1) > 0]  # Relaxando a condi√ß√£o para permitir mais matches\n",
    "\n",
    "# Exibindo os pares com alta similaridade\n",
    "if not matches.empty:\n",
    "    print(\"\\nPares duplicados encontrados:\")\n",
    "    for index_x, index_y in matches.index:\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "        print(pares_duplicados.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNenhum par duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706518f5-c81e-486a-9b9f-16867b643794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limpeza b√°sica\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# N√∫mero de registros\n",
    "total_linhas = len(df)\n",
    "print(f\"# Base de dados: {total_linhas} registros\")\n",
    "\n",
    "# Criando pares com bloqueio pela vari√°vel 'sexo'\n",
    "indexer = Index()\n",
    "indexer.block('sexo')\n",
    "pares = indexer.index(df)\n",
    "print(f\"# N√∫mero total de pares: {len(pares):,} pares\")\n",
    "print(\"# Bloqueando pela vari√°vel: 'sexo'\\n\")\n",
    "\n",
    "# Comparador\n",
    "compare = Compare()\n",
    "compare.string('nome', 'nome', method='jaro_winkler', threshold=0.7, label='nome')\n",
    "compare.string('cpf', 'cpf', method='jaro_winkler', threshold=0.8, label='cpf')\n",
    "compare.string('nome_mae', 'nome_mae', method='jaro_winkler', threshold=0.8, label='nome_mae')\n",
    "compare.string('data_nasc', 'data_nasc', method='jaro_winkler', threshold=0.6, label='data_nasc')\n",
    "\n",
    "# Computando as similaridades\n",
    "features = compare.compute(pares, df)\n",
    "\n",
    "# Formatando os n√∫meros com 7 casas decimais\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.7f}\")\n",
    "\n",
    "# Adicionando colunas dos √≠ndices .x e .y para facilitar a visualiza√ß√£o\n",
    "features_reset = features.reset_index()\n",
    "\n",
    "# Exibindo os 5 primeiros pares comparados com valores formatados\n",
    "print(\"#       .x   .y     nome      data_nasc   cpf       nome_mae\")\n",
    "for idx, row in features_reset.head(5).iterrows():\n",
    "    print(f\"# {idx+1: <6} {int(row['level_0']): <4} {int(row['level_1']): <4} \"\n",
    "          f\"{row['nome']: <10.7f} {row['data_nasc']: <10.7f} {row['cpf']: <10.7f} {row['nome_mae']: <10.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429feec-2be5-45e1-9a28-794678b44e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ee742-9836-42cb-8735-de6053ff9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import recordlinkage\n",
    "# from recordlinkage import Index, Compare\n",
    "# from recordlinkage.preprocessing import clean\n",
    "\n",
    "# Pr√©-processamento\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# N√∫mero de registros\n",
    "total_linhas = len(df)\n",
    "print(f\"# Base de dados: {total_linhas} registros\")\n",
    "\n",
    "# Indexa√ß√£o por 'sexo'\n",
    "indexer = Index()\n",
    "indexer.block('sexo')\n",
    "pares = indexer.index(df)\n",
    "print(f\"# N√∫mero total de pares: {len(pares):,} pares\")\n",
    "print(\"# Bloqueando pela vari√°vel: 'sexo'\\n\")\n",
    "\n",
    "# Compara√ß√£o\n",
    "compare = Compare()\n",
    "compare.string('nome', 'nome', method='jaro_winkler', threshold=0.7, label='nome')\n",
    "compare.string('cpf', 'cpf', method='jaro_winkler', threshold=0.8, label='cpf')\n",
    "compare.string('nome_mae', 'nome_mae', method='jaro_winkler', threshold=0.8, label='nome_mae')\n",
    "compare.string('data_nasc', 'data_nasc', method='jaro_winkler', threshold=0.6, label='data_nasc')\n",
    "\n",
    "# Executando compara√ß√£o\n",
    "features = compare.compute(pares, df)\n",
    "\n",
    "# Convertendo para DataFrame e resetando √≠ndices\n",
    "resultados = features.reset_index()\n",
    "\n",
    "# Cabe√ßalho com tipo de dados estilo R\n",
    "print(\"#       .x   .y     nome   data_nasc   cpf     nome_mae\")\n",
    "print(\"#    <int> <int>   <num>   <num>       <num>   <num>\")\n",
    "\n",
    "# Exibindo os primeiros pares no formato desejado\n",
    "for i, row in resultados.head(10).iterrows():  # Altere o n√∫mero conforme quiser\n",
    "    print(f\"{i+1}: {row['level_0']} {row['level_1']}  \"\n",
    "          f\"{row['nome']}  {row['data_nasc']}  \"\n",
    "          f\"{row['cpf']:>9.7f}  {row['nome_mae']:>9.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ce455-d864-4045-9256-b7c96a5b3c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
