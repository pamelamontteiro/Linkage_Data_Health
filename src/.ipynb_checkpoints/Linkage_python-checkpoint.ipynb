{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba5605d-603d-40fb-82a1-6a94ad271473",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1005412077.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install pandas\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef130e5a-b280-4228-b70e-f3b7794520a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qgrid\n",
      "  Downloading qgrid-1.3.1.tar.gz (889 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m889.2/889.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting notebook>=4.0.0 (from qgrid)\n",
      "  Downloading notebook-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>=0.18.0 in ./.venv/lib/python3.10/site-packages (from qgrid) (2.2.3)\n",
      "Collecting ipywidgets>=7.0.0 (from qgrid)\n",
      "  Downloading ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->qgrid) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->qgrid) (8.35.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->qgrid) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=7.0.0->qgrid)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets>=7.0.0->qgrid)\n",
      "  Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.0rc0 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (4.4.0)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./.venv/lib/python3.10/site-packages (from notebook>=4.0.0->qgrid) (6.4.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=0.18.0->qgrid) (2025.2)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (4.13.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (23.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (7.7.0)\n",
      "Requirement already satisfied: packaging>=22.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (25.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (26.4.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (0.28.1)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (78.1.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in ./.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2.2.1)\n",
      "Requirement already satisfied: babel>=2.10 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.18.0->qgrid) (1.17.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (21.2.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (0.14.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (1.8.14)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.0rc0->notebook>=4.0.0->qgrid) (7.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (4.3.7)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./.venv/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.0.0->qgrid) (2.4.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.0.0->qgrid) (0.2.3)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.4.0)\n",
      "Requirement already satisfied: fqdn in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (3.0.0)\n",
      "Requirement already satisfied: uri-template in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./.venv/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.6)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./.venv/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./.venv/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->qgrid) (2.9.0.20241206)\n",
      "Downloading ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "Downloading notebook-7.4.0-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: qgrid\n",
      "  Building wheel for qgrid (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for qgrid: filename=qgrid-1.3.1-py2.py3-none-any.whl size=1761343 sha256=98ea9338637a4c3e4ed5dd594b56ecc8b29236f14d138a312c059cfc63b138cb\n",
      "  Stored in directory: /home/pamela/.cache/pip/wheels/b2/28/9b/c1053eb92a506d814e21f415d6ce4beab694a3efed99b500bc\n",
      "Successfully built qgrid\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets, notebook, qgrid\n",
      "Successfully installed ipywidgets-8.1.6 jupyterlab_widgets-3.0.14 notebook-7.4.0 qgrid-1.3.1 widgetsnbextension-4.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install qgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f69f0b66-e8a9-4a61-8810-e35b25f33f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff88b81-6eec-4876-88e6-e1b451c5fea9",
   "metadata": {},
   "source": [
    "# Tabela de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c539c90-beeb-4099-b0e0-c86bc2b6e56e",
   "metadata": {},
   "source": [
    "Carrega a função read_csv() do pacote pandas\n",
    "\n",
    "A função read_csv() é utilizada para ler arquivos CSV em Python.\n",
    "Ao utilizarmos o parâmetro `sep=';'`, indicamos que o separador de colunas do arquivo é o ponto e vírgula (;)\n",
    "Esse é o padrão de separação em muitos arquivos CSV gerados por sistemas brasileiros,\n",
    "como os arquivos exportados de sistemas públicos de saúde\n",
    "\n",
    "Lê o arquivo chamado \"sivep_identificado.csv\", que está dentro da pasta \"DATA\"\n",
    "Este arquivo contém informações de internações por Síndrome Respiratória Aguda Grave (SRAG), incluindo casos de COVID-19\n",
    "A base foi extraída do sistema SIVEP-Gripe, utilizado para registrar e acompanhar esses casos no Brasil\n",
    "O nome do arquivo indica que os dados estão identificados (ou seja, possivelmente contêm nomes ou outros dados sensíveis que permitem identificar os pacientes)\n",
    "\n",
    "A função read_csv() transforma esse arquivo CSV em um objeto do tipo DataFrame, que será armazenado na variável `sivep`\n",
    "Essa variável agora contém toda a base de dados de internações e poderá ser manipulada, filtrada,\n",
    "cruzada com outras bases (como a de óbitos), analisada e visualizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e721940-a81b-4402-8a47-f7d0cca1f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Se os campos são separados por ponto e vírgula (padrão do Brasil, como arquivos do SUS):\n",
    "df = pd.read_csv('/home/pamela/Documentos/Linkage_Data_Health/DATA/sivep_identificado.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2e59b7-6691-4774-b17d-a7966c1a98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nu_notific                       nome       sexo   data_nasc  idade  \\\n",
      "0     10001569      Kauan Azevedo Azevedo  masculino  1965-07-27     57   \n",
      "1     10009876         Raissa Cunha Costa   feminino  1939-07-15     83   \n",
      "2     10012252      Rafael Castro Barbosa  masculino  1976-03-28     46   \n",
      "3     10012410     Vinicius Silva Ribeiro  masculino  1964-02-10     58   \n",
      "4     10017778       Beatriz Araujo Rocha   feminino  1992-03-04     30   \n",
      "..         ...                        ...        ...         ...    ...   \n",
      "95    10187056    Vitoria Correia Almeida   feminino  1979-07-25     43   \n",
      "96    10188551  Carlos Goncalves Carvalho  masculino  1972-12-16     49   \n",
      "97    10188869       Paulo Barros Almeida  masculino  1972-01-09     50   \n",
      "98    10189965   Guilherme Castro Barbosa  masculino  1951-12-04     70   \n",
      "99    10190488       Marisa Ribeiro Pinto   feminino  1961-12-13     60   \n",
      "\n",
      "               cpf                   nome_mae  \n",
      "0   622.290.767-95     Analia Azevedo Azevedo  \n",
      "1   662.957.878-35          Agata Cunha Costa  \n",
      "2   665.935.236-82     Natacha Castro Barbosa  \n",
      "3   532.933.567-10      Aldenir Silva Ribeiro  \n",
      "4   602.213.075-16          Raquel de Miranda  \n",
      "..             ...                        ...  \n",
      "95  155.195.378-10  Cleidiane Correia Almeida  \n",
      "96  121.244.102-88      Hilda Henrique Santos  \n",
      "97  337.997.565-66      Natali Barros Almeida  \n",
      "98  832.643.843-02    Grasiele Castro Barbosa  \n",
      "99  935.870.221-43        Aracy Ribeiro Pinto  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostra as primeiras linhas\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a2a02-8169-4619-824e-3628f88aa967",
   "metadata": {},
   "source": [
    "A visualização abaixo mostra as primeiras linhas do DataFrame `sivep`, que contém informações sobre internações\n",
    "por Síndrome Respiratória Aguda Grave (SRAG), extraídas do sistema SIVEP-Gripe.\n",
    "Cada linha representa um paciente e as colunas trazem atributos relacionados à identificação e características individuais.\n",
    "\n",
    "Explicação das colunas apresentadas:\n",
    "- nu_notific: número da notificação (identificador único do registro)\n",
    "- nome: nome completo do paciente\n",
    "- sexo: sexo biológico (masculino/feminino)\n",
    "- data_nasc: data de nascimento\n",
    "- idade: idade do paciente no momento da notificação\n",
    "- cpf: número do CPF do paciente\n",
    "- nome_mae: nome completo da mãe do paciente\n",
    "\n",
    "Essa tabela é útil para realizar análises de perfil demográfico, validar registros por linkage com outras bases (ex: óbitos),\n",
    "ou realizar estudos epidemiológicos sobre os casos registrados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4cd232-a895-42a2-b6d3-537841abf8ef",
   "metadata": {},
   "source": [
    "# 2. Gerando e filtrando os pares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d172cd5-1e6b-4a6e-995a-6a4012e4e2ae",
   "metadata": {},
   "source": [
    "\n",
    "Realizando a blocagem dos dados pela variável \"sexo\"\n",
    "A função 'pair_blocking' do pacote 'reclin' é utilizada para blocar os dados\n",
    "especificando que a comparação será feita com base na variável \"sexo\".\n",
    "Isso ajuda a reduzir a quantidade de pares a serem comparados.\n",
    "O argumento 'deduplication = TRUE' indica que estamos realizando a deduplicação,\n",
    "ou seja, comparando o banco de dados consigo mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e1feec9-f8c9-4681-b0fd-1952cd568a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nu_notific', 'nome', 'sexo', 'data_nasc', 'idade', 'cpf', 'nome_mae'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verificar as colunas para garantir que 'sexo' está presente\n",
    "print(df.columns)\n",
    "df=df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47909a-3fb4-4900-86d0-d658537bb679",
   "metadata": {},
   "source": [
    "Index(['nu_notific', 'nome', 'sexo', 'data_nasc', 'idade', 'cpf', 'nome_mae'], dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16c2fe5a-4b73-4ab2-aa2d-74fbcad37fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pares encontrados: 2454\n"
     ]
    }
   ],
   "source": [
    "# Realizando a blocagem dos dados pela variável \"sexo\"\n",
    "pares_blocagem = []\n",
    "\n",
    "# Agrupar os dados pelo sexo\n",
    "for sexo, grupo in df.groupby('sexo'):\n",
    "    # Para cada grupo, realizar a comparação de todos os pares dentro do grupo\n",
    "    for i in range(len(grupo)):\n",
    "        for j in range(i + 1, len(grupo)):\n",
    "            pares_blocagem.append((grupo.iloc[i], grupo.iloc[j]))\n",
    "\n",
    "# Convertendo a lista de pares em um DataFrame para visualização\n",
    "pares_blocagem_df = pd.DataFrame(pares_blocagem, columns=['Registro_1', 'Registro_2'])\n",
    "\n",
    "# Exibindo as primeiras linhas da tabela resultante da blocagem\n",
    "pares_blocagem_df.head()\n",
    "\n",
    "# Contando o total de pares encontrados\n",
    "total_pares = len(pares_blocagem_df)\n",
    "print(f'Total de pares encontrados: {total_pares}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "631a6e91-9588-4c4f-a9fa-13dd450f93f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: recordlinkage in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (0.16)\n",
      "Requirement already satisfied: jellyfish>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (2.2.4)\n",
      "Requirement already satisfied: pandas<3,>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.6.1)\n",
      "Requirement already satisfied: joblib in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from recordlinkage) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from pandas<3,>=1->recordlinkage) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from pandas<3,>=1->recordlinkage) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from pandas<3,>=1->recordlinkage) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from scikit-learn>=1->recordlinkage) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1->recordlinkage) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install recordlinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb691e3-4482-4219-b2af-056a1a20ef17",
   "metadata": {},
   "source": [
    "# 3. Aplicando o método de linkage determinístico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bfca0-1e2c-4a2d-a98a-46dc6cf61723",
   "metadata": {},
   "source": [
    "### 🔧 import recordlinkage\n",
    "\n",
    "Esse comando importa o pacote inteiro, permitindo acesso a todos os seus módulos, como:\n",
    "\n",
    "**recordlinkage.Index()** – para definir blocagens e gerar pares de registros;\n",
    "\n",
    "**recordlinkage.Compare()** – para comparar os pares gerados e calcular similaridades;\n",
    "\n",
    "**recordlinkage.ECMClassifier()** – um classificador probabilístico para decidir se pares são correspondências.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301cc38-9867-4884-a68f-c10c58632a82",
   "metadata": {},
   "source": [
    "### from recordlinkage import Compare\n",
    "Esse comando importa só a **classe Compare**, usada para:\n",
    "\n",
    "✅ Definir como os registros serão comparados\n",
    "Você define as variáveis a comparar, e o método de comparação (ex: Jaro-Winkler, exata, Levenshtein etc).\n",
    "\n",
    "✅ Calcular a similaridade dos pares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "657f50c4-41b8-403d-9344-ccb6768396f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage import Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb322642-75b5-424b-ae40-c9fe5cf1ce3b",
   "metadata": {},
   "source": [
    "Agora aplicaremos o linkage do tipo determinístico. Isto porque com ele o pareamento dos indivíduos no banco de dados é feito pela correspondência exata entre registros. Vamos lá!\n",
    "\n",
    "Como primeira etapa, iremos realizar o linkage informando quais variáveis queremos comparar. Em nosso exemplo, iremos utilizar as variáveis nome, data de nascimento, cpf e nome da mãe.\n",
    "\n",
    "Então precisaremos comparar se os valores das variáveis são iguais. Ao aplicar esta etapa poderemos obter os valores TRUE (verdadeiro) ou FALSE (falso). Para que você possa compreender melhor, se um par de registros no qual as quatro variáveis escolhidas fossem TRUE (verdadeiras) representaria um linkage com alta acurácia entre estes registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "261ad7dd-41da-418e-a0a0-b568c591f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criando o indexador e fazendo a blocagem por 'sexo'\n",
    "indexador = Index()\n",
    "indexador.block('sexo')\n",
    "\n",
    "# Gerando os pares de blocagem (isso retorna um pandas.MultiIndex)\n",
    "pares_blocagem = indexador.index(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "89c76cba-6b53-494c-9a3b-3d5e64fe1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_comparacao = compare.compute(pares_blocagem, df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b326d4e-8640-4433-9b66-8f454256e234",
   "metadata": {},
   "source": [
    "**Compare()**.exact(...): compara os valores de forma exata.\n",
    "\n",
    "**pares_iguais**: guarda apenas os pares em que todas as variáveis são `iguais (1.0)`.\n",
    "\n",
    "**block('sexo')**: opcional, usado para reduzir o número de pares comparados, fazendo comparações só dentro de grupos (por exemplo, homens com homens e mulheres com mulheres).\n",
    "\n",
    "Ao final, o código imprime os pares de registros que batem exatamente em todas as variáveis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f7ce9cd-1821-43c6-9bfb-e698cd34232b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x     y  nome  data_nasc   cpf  nome_mae\n",
      "0   528  3372  True       True  True      True\n",
      "1   933  6984  True       True  True      True\n",
      "2   978  3026  True       True  True      True\n",
      "3  1023  9323  True       True  True      True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suponha que você tenha um DataFrame de exemplo como este:\n",
    "# O DataFrame 'p_deter' é o resultado da comparação entre os registros, \n",
    "# onde as colunas 'nome', 'data_nasc', 'cpf' e 'nome_mae' contêm valores booleanos.\n",
    "# Aqui, vamos criar um DataFrame fictício para simular o exemplo:\n",
    "\n",
    "data = {\n",
    "    'x': [528, 933, 978, 1023],\n",
    "    'y': [3372, 6984, 3026, 9323],\n",
    "    'nome': [True, True, True, True],\n",
    "    'data_nasc': [True, True, True, True],\n",
    "    'cpf': [True, True, True, True],\n",
    "    'nome_mae': [True, True, True, True]\n",
    "}\n",
    "\n",
    "# Criando o DataFrame\n",
    "p_deter = pd.DataFrame(data)\n",
    "\n",
    "# Filtrando os pares com correspondência exata em todas as variáveis\n",
    "pares_iguais = p_deter[\n",
    "    p_deter[['nome', 'data_nasc', 'cpf', 'nome_mae']].all(axis=1)\n",
    "]\n",
    "\n",
    "# Exibindo os pares com correspondência perfeita\n",
    "print(pares_iguais)\n",
    "\n",
    "# A saída será algo assim:\n",
    "#       x     y   nome  data_nasc   cpf  nome_mae\n",
    "# 0   528  3372   True   True     True    True\n",
    "# 1   933  6984   True   True     True    True\n",
    "# 2   978  3026   True   True     True    True\n",
    "# 3  1023  9323   True   True     True    True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcc612-b306-4ff3-a5f2-fa6f80d171ce",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " A saída será algo assim:\n",
    " | x   |  y  | nome | data_nasc  | cpf |nome_mae|\n",
    "| ------  | :-----------------------: | ------  | :-----------------------: | ------  | :-----------------------: |\n",
    "| 0   |528 | 3372  | True   |True |    True|    True|\n",
    "| 1  | 933 | 6984 |  True |  True |    True|   True|\n",
    "| 2  | 978 | 3026 |  True  | True |  True |   True|\n",
    "| 3  |1023 | 9323 |  True  | True  |   True |   True|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19b08f-3cc9-45a9-a340-ccfb87687f87",
   "metadata": {},
   "source": [
    "Esse resultado mostra os pares de registros que foram identificados como iguais em todas as variáveis comparadas — ou seja, possivelmente registros duplicados no seu dataset.\n",
    "\n",
    "\n",
    "📋 Descrição do Resultado\n",
    "\n",
    "| Coluna | Significado |\n",
    "| ------  | :-----------------------: |\n",
    "| `x` |\tÍndice do primeiro registro no par comparado|\n",
    "| `y`\t|  Índice do segundo registro no par comparado |\n",
    "| `nome` | `True` indica que os valores de nome são iguais nos dois registros |\n",
    "| `data_nasc`\t| `True` indica que as datas de nascimento também batem exatamente |\n",
    "| `cpf` |\t`True` significa que os dois registros têm o mesmo CPF |\n",
    "| `nome_mae` |\t`True` indica que os nomes das mães são iguais |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8782ebc-b6c1-44e7-91ed-6929f47389e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /home/pamela/Documentos/Linkage_Data_Health/.venv/lib/python3.10/site-packages (0.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ff666-a755-426e-beca-276a109a24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f1145-60f0-4cf2-9262-839c9abdf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique o número de linhas no DataFrame# Verifique os índices em 'pares_iguais'\n",
    "print(pares_iguais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbb7c0-f265-4efb-b92b-7b592c6ebe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique o número de linhas no DataFrame\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefc0f7-2c19-46c3-8923-d6eea6e037c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique o número de linhas no DataFrame\n",
    "print(f\"Total de linhas no DataFrame: {len(df)}\")\n",
    "\n",
    "# Suponha que 'pares_iguais' seja um DataFrame com os índices dos pares duplicados\n",
    "# Exemplo de pares_iguais (índices das linhas duplicadas)\n",
    "pares_iguais = pd.DataFrame({'x': [528, 1034], 'y': [3372, 2104]})\n",
    "\n",
    "# Verifique se os índices estão dentro do intervalo\n",
    "if (pares_iguais['x'][0] < len(df)) and (pares_iguais['y'][0] < len(df)):\n",
    "    # Selecionando as linhas correspondentes aos índices dos pares duplicados\n",
    "    registro_1 = df.iloc[pares_iguais['x'][0]]\n",
    "    registro_2 = df.iloc[pares_iguais['y'][0]]\n",
    "\n",
    "    # Concatenando as duas linhas para visualização\n",
    "    pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "\n",
    "    # Exibindo as duas linhas duplicadas em formato de tabela bonita\n",
    "    print(tabulate(pares_duplicados, headers='keys', tablefmt='pretty'))\n",
    "else:\n",
    "    print(\"Índices fora do intervalo do DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919c6cb-55f0-44a9-8568-5032601eb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verifique o número de linhas no DataFrame\n",
    "total_linhas = len(df)\n",
    "print(f\"Total de linhas no DataFrame: {total_linhas}\")\n",
    "\n",
    "# Suponha que 'pares_iguais' seja um DataFrame com os índices dos pares duplicados\n",
    "# Exemplo de pares_iguais (índices das linhas duplicadas)\n",
    "pares_iguais = pd.DataFrame({'x': [528, 1034], 'y': [3372, 2104]})\n",
    "\n",
    "# Verifique os índices em 'pares_iguais'\n",
    "print(\"Índices em pares_iguais:\")\n",
    "print(pares_iguais)\n",
    "\n",
    "# Verifique se os índices estão dentro do intervalo\n",
    "for index_x, index_y in zip(pares_iguais['x'], pares_iguais['y']):\n",
    "    if index_x < total_linhas and index_y < total_linhas:\n",
    "        # Selecionando as linhas correspondentes aos índices dos pares duplicados\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "\n",
    "        # Concatenando as duas linhas para visualização\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "\n",
    "        # Exibindo as duas linhas duplicadas em formato de tabela bonita\n",
    "        print(tabulate(pares_duplicados, headers='keys', tablefmt='pipe', showindex=False))\n",
    "    else:\n",
    "        print(f\"Índices {index_x} ou {index_y} estão fora do intervalo do DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224eb5fa-3d67-42e8-8b0a-78d8aba740a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando pares_iguais para manter apenas os índices dentro do intervalo\n",
    "pares_iguais_filtrados = pares_iguais[(pares_iguais['x'] < total_linhas) & (pares_iguais['y'] < total_linhas)]\n",
    "\n",
    "# Verifique os pares filtrados\n",
    "print(\"Pares de índices válidos:\")\n",
    "print(pares_iguais_filtrados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53436e-2443-4342-b8c5-f0f44bfafa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste manual dos índices (caso você saiba que esses são inválidos)\n",
    "pares_iguais.loc[0, 'x'] = 10  # Ajuste o índice conforme necessário\n",
    "pares_iguais.loc[0, 'y'] = 20  # Ajuste o índice conforme necessário\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1375de2-9d2b-4868-bcb3-0807a9e17e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando pares_iguais para garantir que os índices estão dentro do intervalo\n",
    "pares_iguais_filtrados = pares_iguais[(pares_iguais['x'] < total_linhas) & (pares_iguais['y'] < total_linhas)]\n",
    "\n",
    "# Se houver pares válidos\n",
    "if not pares_iguais_filtrados.empty:\n",
    "    for index_x, index_y in zip(pares_iguais_filtrados['x'], pares_iguais_filtrados['y']):\n",
    "        # Selecionando as linhas correspondentes aos índices dos pares duplicados\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "\n",
    "        # Concatenando as duas linhas para visualização\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "\n",
    "        # Exibindo as duas linhas duplicadas em formato de tabela bonita\n",
    "        print(tabulate(pares_duplicados, headers='keys', tablefmt='pipe', showindex=False))\n",
    "else:\n",
    "    print(\"Nenhum índice válido encontrado em pares_iguais\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eae549-9dc2-4b8d-b369-e57a87c2c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage import compare\n",
    "from recordlinkage.index import Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e861ff-bf55-40e1-a862-456e044e1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pares_blocagem.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ab893-03d7-4259-b10e-e44b97e72903",
   "metadata": {},
   "outputs": [],
   "source": [
    "pares_blocagem.rename(columns={'nome_coluna_diferente': 'nome'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42c10f-8a8c-46ec-b4d6-44306a34c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pares_blocagem.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4d961-aab1-48cb-bd6c-92a09e54c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install recordlinkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b734b2c-10ef-4ead-83e4-bbc513826ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage import Index\n",
    "from recordlinkage.preprocessing import clean\n",
    "from recordlinkage import Compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd599dda-fc6a-4e54-b8fd-5afa6645622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supondo que você tenha um DataFrame 'df' com as colunas 'nome', 'data_nasc', 'cpf', 'nome_mae'\n",
    "\n",
    "# Limpeza de dados, como remoção de espaços extras e conversão de maiúsculas/minúsculas\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Criação do índice de comparação\n",
    "indexer = Index()\n",
    "indexer.block('nome')  # Comparando primeiro pelo nome\n",
    "pairs = indexer.index(df)\n",
    "\n",
    "# Comparação de pares\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Adicionando comparações para as colunas\n",
    "compare.string('nome', 'nome', threshold=0.9, label='nome')\n",
    "compare.string('cpf', 'cpf', threshold=0.9, label='cpf')\n",
    "compare.string('nome_mae', 'nome_mae', threshold=0.9, label='nome_mae')\n",
    "compare.string('data_nasc', 'data_nasc', threshold=0.9, label='data_nasc')\n",
    "\n",
    "# Comparando os pares\n",
    "features = compare.compute(pairs, df)\n",
    "\n",
    "# Resultados: Filtrando os pares com alta similaridade\n",
    "matches = features[features.sum(axis=1) > 2]  # Ajuste o número conforme necessário\n",
    "\n",
    "# Exibindo os pares com alta similaridade\n",
    "if not matches.empty:\n",
    "    for index_x, index_y in matches.index:\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "        print(pares_duplicados.to_string(index=False))\n",
    "else:\n",
    "    print(\"Nenhum par duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adb757-805e-4c61-9693-39204126a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import recordlinkage\n",
    "# from recordlinkage import Index\n",
    "# from recordlinkage.preprocessing import clean\n",
    "# from recordlinkage import Compare\n",
    "\n",
    "# Supondo que você tenha um DataFrame 'df' com as colunas 'nome', 'data_nasc', 'cpf', 'nome_mae'\n",
    "\n",
    "# Limpeza de dados, como remoção de espaços extras e conversão de maiúsculas/minúsculas\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Verificando duplicatas diretamente\n",
    "print(df[df.duplicated(subset=['nome', 'cpf', 'nome_mae', 'data_nasc'], keep=False)])\n",
    "\n",
    "# Criação do índice de comparação\n",
    "indexer = Index()\n",
    "indexer.block(['nome', 'data_nasc'])  # Alterando a estratégia de bloqueio\n",
    "pairs = indexer.index(df)\n",
    "\n",
    "# Comparação de pares\n",
    "compare = Compare()\n",
    "\n",
    "# Ajustando os limiares de similaridade para cada coluna usando o método 'string' com 'jaro_winkler'\n",
    "compare.string('nome', 'nome', threshold=0.7, label='nome', method='jaro_winkler')\n",
    "compare.string('cpf', 'cpf', threshold=0.8, label='cpf', method='jaro_winkler')\n",
    "compare.string('nome_mae', 'nome_mae', threshold=0.8, label='nome_mae', method='jaro_winkler')\n",
    "compare.string('data_nasc', 'data_nasc', threshold=0.6, label='data_nasc', method='jaro_winkler')\n",
    "\n",
    "# Comparando os pares\n",
    "features = compare.compute(pairs, df)\n",
    "\n",
    "# Exibindo as comparações para diagnóstico\n",
    "print(features.head())\n",
    "\n",
    "# Resultados: Filtrando os pares com alta similaridade\n",
    "matches = features[features.sum(axis=1) > 0]  # Relaxando a condição para permitir mais matches\n",
    "\n",
    "# Exibindo os pares com alta similaridade\n",
    "if not matches.empty:\n",
    "    for index_x, index_y in matches.index:\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "        print(pares_duplicados.to_string(index=False))\n",
    "else:\n",
    "    print(\"Nenhum par duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbde46-c68c-4f80-9582-67cc4c007102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supondo que você tenha um DataFrame 'df' com as colunas 'nome', 'data_nasc', 'cpf', 'nome_mae'\n",
    "\n",
    "# Limpeza de dados, como remoção de espaços extras e conversão de maiúsculas/minúsculas\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Verificando duplicatas diretamente\n",
    "print(\"Verificando duplicatas diretamente:\")\n",
    "print(df[df.duplicated(subset=['nome', 'cpf', 'nome_mae', 'data_nasc'], keep=False)])\n",
    "\n",
    "# Criando o índice de comparação\n",
    "indexer = Index()\n",
    "indexer.block(['sexo'])  # Alterando a estratégia de bloqueio para 'sexo' (ajuste conforme necessário)\n",
    "pairs = indexer.index(df)\n",
    "\n",
    "# Exibindo o número total de pares\n",
    "print(f\"\\nNúmero total de pares: {len(pairs)} pares\")\n",
    "\n",
    "# Comparação de pares\n",
    "compare = Compare()\n",
    "\n",
    "# Ajustando os limiares de similaridade para cada coluna usando o método 'string' com 'jaro_winkler'\n",
    "compare.string('nome', 'nome', threshold=0.7, label='nome', method='jaro_winkler')\n",
    "compare.string('cpf', 'cpf', threshold=0.8, label='cpf', method='jaro_winkler')\n",
    "compare.string('nome_mae', 'nome_mae', threshold=0.8, label='nome_mae', method='jaro_winkler')\n",
    "compare.string('data_nasc', 'data_nasc', threshold=0.6, label='data_nasc', method='jaro_winkler')\n",
    "\n",
    "# Comparando os pares\n",
    "features = compare.compute(pairs, df)\n",
    "\n",
    "# Exibindo o resumo de similaridade\n",
    "print(\"\\nResumo da similaridade:\")\n",
    "print(features.head())\n",
    "\n",
    "# Filtrando os pares com alta similaridade\n",
    "matches = features[features.sum(axis=1) > 0]  # Relaxando a condição para permitir mais matches\n",
    "\n",
    "# Exibindo os pares com alta similaridade\n",
    "if not matches.empty:\n",
    "    print(\"\\nPares duplicados encontrados:\")\n",
    "    for index_x, index_y in matches.index:\n",
    "        registro_1 = df.iloc[index_x]\n",
    "        registro_2 = df.iloc[index_y]\n",
    "        pares_duplicados = pd.concat([registro_1, registro_2], axis=1).T\n",
    "        print(pares_duplicados.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNenhum par duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706518f5-c81e-486a-9b9f-16867b643794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limpeza básica\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Número de registros\n",
    "total_linhas = len(df)\n",
    "print(f\"# Base de dados: {total_linhas} registros\")\n",
    "\n",
    "# Criando pares com bloqueio pela variável 'sexo'\n",
    "indexer = Index()\n",
    "indexer.block('sexo')\n",
    "pares = indexer.index(df)\n",
    "print(f\"# Número total de pares: {len(pares):,} pares\")\n",
    "print(\"# Bloqueando pela variável: 'sexo'\\n\")\n",
    "\n",
    "# Comparador\n",
    "compare = Compare()\n",
    "compare.string('nome', 'nome', method='jaro_winkler', threshold=0.7, label='nome')\n",
    "compare.string('cpf', 'cpf', method='jaro_winkler', threshold=0.8, label='cpf')\n",
    "compare.string('nome_mae', 'nome_mae', method='jaro_winkler', threshold=0.8, label='nome_mae')\n",
    "compare.string('data_nasc', 'data_nasc', method='jaro_winkler', threshold=0.6, label='data_nasc')\n",
    "\n",
    "# Computando as similaridades\n",
    "features = compare.compute(pares, df)\n",
    "\n",
    "# Formatando os números com 7 casas decimais\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.7f}\")\n",
    "\n",
    "# Adicionando colunas dos índices .x e .y para facilitar a visualização\n",
    "features_reset = features.reset_index()\n",
    "\n",
    "# Exibindo os 5 primeiros pares comparados com valores formatados\n",
    "print(\"#       .x   .y     nome      data_nasc   cpf       nome_mae\")\n",
    "for idx, row in features_reset.head(5).iterrows():\n",
    "    print(f\"# {idx+1: <6} {int(row['level_0']): <4} {int(row['level_1']): <4} \"\n",
    "          f\"{row['nome']: <10.7f} {row['data_nasc']: <10.7f} {row['cpf']: <10.7f} {row['nome_mae']: <10.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429feec-2be5-45e1-9a28-794678b44e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ee742-9836-42cb-8735-de6053ff9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import recordlinkage\n",
    "# from recordlinkage import Index, Compare\n",
    "# from recordlinkage.preprocessing import clean\n",
    "\n",
    "# Pré-processamento\n",
    "df['nome'] = clean(df['nome'])\n",
    "df['cpf'] = clean(df['cpf'])\n",
    "df['nome_mae'] = clean(df['nome_mae'])\n",
    "df['data_nasc'] = clean(df['data_nasc'])\n",
    "\n",
    "# Número de registros\n",
    "total_linhas = len(df)\n",
    "print(f\"# Base de dados: {total_linhas} registros\")\n",
    "\n",
    "# Indexação por 'sexo'\n",
    "indexer = Index()\n",
    "indexer.block('sexo')\n",
    "pares = indexer.index(df)\n",
    "print(f\"# Número total de pares: {len(pares):,} pares\")\n",
    "print(\"# Bloqueando pela variável: 'sexo'\\n\")\n",
    "\n",
    "# Comparação\n",
    "compare = Compare()\n",
    "compare.string('nome', 'nome', method='jaro_winkler', threshold=0.7, label='nome')\n",
    "compare.string('cpf', 'cpf', method='jaro_winkler', threshold=0.8, label='cpf')\n",
    "compare.string('nome_mae', 'nome_mae', method='jaro_winkler', threshold=0.8, label='nome_mae')\n",
    "compare.string('data_nasc', 'data_nasc', method='jaro_winkler', threshold=0.6, label='data_nasc')\n",
    "\n",
    "# Executando comparação\n",
    "features = compare.compute(pares, df)\n",
    "\n",
    "# Convertendo para DataFrame e resetando índices\n",
    "resultados = features.reset_index()\n",
    "\n",
    "# Cabeçalho com tipo de dados estilo R\n",
    "print(\"#       .x   .y     nome   data_nasc   cpf     nome_mae\")\n",
    "print(\"#    <int> <int>   <num>   <num>       <num>   <num>\")\n",
    "\n",
    "# Exibindo os primeiros pares no formato desejado\n",
    "for i, row in resultados.head(10).iterrows():  # Altere o número conforme quiser\n",
    "    print(f\"{i+1}: {row['level_0']} {row['level_1']}  \"\n",
    "          f\"{row['nome']}  {row['data_nasc']}  \"\n",
    "          f\"{row['cpf']:>9.7f}  {row['nome_mae']:>9.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ce455-d864-4045-9256-b7c96a5b3c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
